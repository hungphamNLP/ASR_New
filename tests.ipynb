{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 01:55:02.706034: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Generator\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import whisper\n",
    "import IPython.display as ipd\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "import model2\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dims', 'model_state_dict'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_mels': 80,\n",
       " 'n_vocab': 51865,\n",
       " 'n_audio_ctx': 1500,\n",
       " 'n_audio_state': 384,\n",
       " 'n_audio_head': 6,\n",
       " 'n_audio_layer': 4,\n",
       " 'n_text_ctx': 448,\n",
       " 'n_text_state': 384,\n",
       " 'n_text_head': 6,\n",
       " 'n_text_layer': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whisper_path = Path(\"./checkpoint/tiny.pt\").expanduser()  # download the weights first using official whisper\n",
    "with open(whisper_path, \"rb\") as f:\n",
    "    checkpoint = torch.load(f)\n",
    "ipd.display(checkpoint.keys())\n",
    "ipd.display(checkpoint[\"dims\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = whisper.load_model(\"tiny\", device=\"cpu\").eval()  # original model loading\n",
    "model_dims = model2.ModelDimensions(**checkpoint[\"dims\"])\n",
    "modded = model2.Whisper(model_dims).eval()\n",
    "modded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "scripted = torch.jit.script(modded).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 384)\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiolist = [\n",
    "    \"tests/jfk.flac\",\n",
    "    \"tests/jfk_noise_front.wav\",\n",
    "    \"tests/jfk_noise_middle.wav\",\n",
    "    \"tests/jfk_noise_back.wav\",\n",
    "    \"tests/noise_only.wav\",\n",
    "    \"tests/debussy.wav\",\n",
    "]\n",
    "audio = whisper.load_audio(audiolist[2])\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387],\n",
       "         [-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387],\n",
       "         [-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387],\n",
       "         ...,\n",
       "         [-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387],\n",
       "         [-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387],\n",
       "         [-0.5387, -0.5387, -0.5387,  ..., -0.5387, -0.5387, -0.5387]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_encoded = ori.encoder(mel)\n",
    "modded_encoded = modded.encoder(mel)\n",
    "scripted_encoded = scripted.encoder(mel)\n",
    "\n",
    "assert torch.allclose(ori_encoded, modded_encoded)\n",
    "assert torch.allclose(ori_encoded, scripted_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple decoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is <|startoftranscript|><|en|><|transcribe|><|notimestamps|> from gpt2 tokenizer\n",
    "tokens = torch.tensor([50258, 50259, 50359, 50363]).unsqueeze(0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_decoded = ori.decoder(tokens, ori_encoded)\n",
    "modded_decoded = modded.decoder(tokens, ori_encoded, {})\n",
    "scripted_decoded = scripted.decoder(tokens, ori_encoded, {})\n",
    "\n",
    "assert torch.allclose(ori_decoded, modded_decoded)\n",
    "assert torch.allclose(ori_decoded, scripted_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='whisper/assets/whisper_mult_gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'additional_special_tokens': ['<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|iw|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nospeech|>', '<|notimestamps|>']})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the already built tokenizer, no need to add manually\n",
    "# only works for multilingual for now\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"whisper/assets/whisper_mult_gpt2\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppressed tokens, see SuppressBlank and SuppressTokens class\n",
    "suppress_blanks = [220, 50257]\n",
    "suppress_nonspeech = [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, \n",
    "    93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, \n",
    "    3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, \n",
    "    14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, \n",
    "    32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50259, 50359, 50363]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"<|startoftranscript|><|en|><|transcribe|><|notimestamps|>\", return_tensors=\"pt\")\n",
    "tokens, tokens.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ori' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     options \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mDecodingOptions(language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m, fp16\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, without_timestamps\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m     ori_transcribed \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mdecode(ori, mel, options)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(ori_transcribed[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ori' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    options = whisper.DecodingOptions(language=\"en\", fp16=False, without_timestamps=True)\n",
    "    ori_transcribed = whisper.decode(ori, mel, options)\n",
    "    print(ori_transcribed[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And so my fellow Americans......Ask not! What your country can do for you......Ask what you can do for your country.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    modded_transcribed = modded.greedy_decode(tokens, mel, suppress_blanks, suppress_nonspeech)\n",
    "    print(tokenizer.batch_decode(modded_transcribed, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load('./checkpoint/tiny_asr.pth')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And so my fellow Americans......Ask not! What your country can do for you......Ask what you can do for your country.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scripted_transcribed = scripted.greedy_decode(tokens.to(device), mel.to(device), suppress_blanks, suppress_nonspeech)\n",
    "    print(tokenizer.batch_decode(scripted_transcribed, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted.save('./checkpoint/tiny_asr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('./checkpoint/tiny_asr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(nn.Module):\n",
    "    \n",
    "    def __init__(self, keygen: Generator) -> None:\n",
    "        super().__init__()\n",
    "        self.unique_num = next(keygen)\n",
    "        self.unique_num = next(keygen)\n",
    "        self.lin = nn.Linear(4, 4)\n",
    "    \n",
    "    def forward(self, x: Tensor, cache: dict[int, Tensor]):\n",
    "        if self.unique_num not in cache:\n",
    "            cache[self.unique_num] = self.lin(x)\n",
    "        return cache[self.unique_num]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def generate(self, x: Tensor):\n",
    "        print(self.unique_num)\n",
    "        cache: dict[int, Tensor] = {}\n",
    "        a = self.forward(x, cache)\n",
    "        b = self.forward(x*2, cache)\n",
    "        return a-b\n",
    "\n",
    "keygen = itertools.count()\n",
    "dummy = Dummy(keygen)\n",
    "sdummy = torch.jit.script(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/evan/Documents/whisper-torchscript/tests.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m net \u001b[39m=\u001b[39m Net()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m net\u001b[39m.\u001b[39;49meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1858\u001b[0m, in \u001b[0;36mModule.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m   1843\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the module in evaluation mode.\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[39m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1837\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mbool\u001b[39m):\n\u001b[1;32m   1836\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m   1839\u001b[0m     module\u001b[39m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1242\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[39melif\u001b[39;00m modules \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1241\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1242\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m as child module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m(torch.nn.Module or None expected)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m                         \u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1245\u001b[0m     modules[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1246\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.training = nn.Linear(5, 4)  # hmm\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c788065d0627783e03f01588c616fdc081ccf79059243dc851e48ed3fc07eef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
